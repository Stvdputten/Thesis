\chapter{Research Background}  \label{ch:theory}

Theory

\section{definitions}

This section contains the research background relevant to our current research. Latent Dirichlet Allocation (LDA) was introduced in 2003 by \cite{Blei2003LatentAllocation}. LDA is used for topic modeling on a corpera of documents. A lot of research has been performed in this area for different uses. The application of LDA ranges from image recognition to simple document topic discovery. 
In the following sections these different applications will be discussed.

\section{Related work} 
Similair research to our research can 

An interesting adaption of topic modelling can be found in twitter and cyber security. Twitter is a interesting field of research with real time tweets and a huge community. Due to the nature of twitter, analysing the huge stream of tweets can be a challenging and exhaustive task. A model with LDA has been introduced to analyse and detect topics, which could make it an interesting way to provide news feeds even quicker then traditional news sites \cite{Zhao2011ComparingModels}. Cyber security has also been an area which LDA seems applicable to. Through the usage of Big data and combination of LDA, users could be identified through system and network logs. Using the event logs to identify topics, new events of users could be identified as malicious or normal \cite{Jingwei2014KnowledgeLDA}. 



\section{Buiding blocks}
To even analyse and compute the system logs discussed in this research existing frameworks and libraries had to be used. Software is required to perform extracting, loading and transforming the data in a useable form.

\subsection{Software}
In this section we discuss the various tools used. There a lot more tools, but these tools are chosen mainly because they are open source and relative easy to use.

\begin{enumerate}
    \item \textbf{Hadoop} $($\url{http://hadoop.apache.org/}$)$ \\
    The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. 
    \begin{enumerate}
        \item \textbf{Apache Spark} $($\url{https://spark.apache.org/}$)$\\
        Apache Spark is a fast and general engine for large-scale data processing. Spark lets users compute in multiple languages.
        \item \textbf{HDFS} $($\url{http://hadoop.apache.org/}$)$ \\
         A distributed file system that provides high-throughput access to application data.
         \item \textbf{Apache Zeppelin} $($\url{https://zeppelin.apache.org/}$)$ \\
         Web-based notebook that enables data-driven, interactive data analytics and collaborative documents with SQL, Scala and more.
    \end{enumerate}
    
    \item \textbf{Scikit-learn} $($\url{http://scikit-learn.org/}$)$ \\
    The Scikit-learn package contains tools for effici\"ent data mining and data analysis with machine learning in Python.
    \begin{enumerate}
        \item \textbf{Pandas} $($\url{http://pandas.pydata.org/}$)$ \\
        Pandas is a library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.
        \item \textbf{Numpy} $($\url{http://www.numpy.org/}$)$ \\
        Numpy is a scientific package with Python for powerful array objects, functions and lots of mathematical capabilities.
        \item \textbf{Matplotlib} $($\url{http://matplotlib.org/}$)$ \\
        Matplotlib is a 2D Python plotting library very similar to MATLAB.
        
    \end{enumerate}
    
\end{enumerate}

\section{Machine learning}
In the field of computer science, machine learning is used to learn computers to classify or predict without explicitly being told to. Learning can be done supervised, unsupervised and semi-supervised. Supervised learning makes use of labeled data, which makes it easy to train and evaluate the model. Unsupervised learning makes use of unlabeled data by recognizing patterns in the data. Semi-supervised learns using both unlabelled and labelled data.

\subsection{Hard and Soft clustering}
While hard and soft clustering are both a form of clustering, this researches contains both forms. The results discussed in chapter \ref{ch:result} contains results based both upon hard and soft clustering. Clustering data can be achieved by giving every element of the data at most 1 label, this is called hard clustering. Soft clustering allows data to be part of multiple clusters or contain multiple labels. Especially when talking about topic modelling, every document is a mixture of multiple topics this by itself is already a form of soft clustering. To avoid confusion what this research means with clustering, this section was added.

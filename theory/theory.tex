\chapter{Research Background}  \label{ch:theory}

TODO Finish this chapter \ldots\ and the rest!


\section{definitions}

\section{Related work}  

This section contains the research background relevant to our current research. Research conducted in 
Latent Dirichlet Allocation (LDA) was introduced in 2003 by \cite{Blei2003LatentAllocation}. LDA is used for topic modeling on a corpera of documents. A lot of research has been performed in this area for different uses. The application of LDA ranges from image recognition to simple document topic discovery. LDA  In the following sections these different applications will be discussed.

\section{Buiding blocks}
To even analyse and compute the system logs discussed in this research existing frameworks and libraries had to be used. Software is required to perform extracting, loading and transforming the data in a useable form.

\subsection{Software}
In this section we discuss the various tools used. There a lot more tools, but these tools are chosen mainly because they are open source and relative easy to use.

\begin{enumerate}
    \item \textbf{Hadoop} $($\url{http://hadoop.apache.org/}$)$ \\
    The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. 
    \begin{enumerate}
        \item \textbf{Apache Spark} $($\url{https://spark.apache.org/}$)$\\
        Apache Spark is a fast and general engine for large-scale data processing. Spark lets users compute in multiple languages.
        \item \textbf{HDFS} $($\url{http://hadoop.apache.org/}$)$ \\
         A distributed file system that provides high-throughput access to application data.
         \item \textbf{Apache Zeppelin} $($\url{https://zeppelin.apache.org/}$)$ \\
         Web-based notebook that enables data-driven, interactive data analytics and collaborative documents with SQL, Scala and more.
    \end{enumerate}
    
    \item \textbf{Scikit-learn} $($\url{http://scikit-learn.org/}$)$ \\
    The Scikit-learn package contains tools for effici\"ent data mining and data analysis with machine learning in Python.
    \begin{enumerate}
        \item \textbf{Pandas} $($\url{http://pandas.pydata.org/}$)$ \\
        Pandas is a library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.
        \item \textbf{Numpy} $($\url{http://www.numpy.org/}$)$ \\
        Numpy is a scientific package with Python for powerful array objects, functions and lots of mathematical capabilities.
        \item \textbf{Matplotlib} $($\url{http://matplotlib.org/}$)$ \\
        Matplotlib is a 2D Python plotting library very similar to MATLAB.
        
    \end{enumerate}
    
\end{enumerate}

\section{Dataset}
The dataset was provided by Capgemini containing vrops, metering and syslogs. Eventually syslogs were chose as suitable data set for analysis. 

\section{Evaluation Measures}
To evaluate our implementation we use different metrics. Evaluating an unsupervised learning model depends on the application and the goal the model is made with. In our case the metrics are here to evaluate the models capability to generalise, using perplexity. The clusters are evaluated based on their inner similarity between documents and \" distance \" compared to other cluster centroids, using Silhouette co\"efficient. The distance metric used for silhouette co\"efficient is based on the KL-divergence metric. Human perception is also an important factor to evaluate the models, which isn't used in this research but we will discussion shortly.

\subsection{Perplexity}\label{research:perplexity}
In the original paper Blei introduces a general model evaluation metric \cite{Blei2003} to compare topic models. Perplexity can be used to compare the generalisation of a model on new unlabelled data.

\[
   \mathlarger{perplexity(\textbf{D}_{test}) = \exp{\Bigg \{ -\frac{\sum{}_{d=1}^{M}logp(\textbf{w}_d)}{\sum{}_{d=1}^{M}N_d} \Bigg \}}}
\]

Perplexity shows the perplexity on the test set of held out documents $\textbf{D}$. The nominator shows the sum in  corpus $M$ with document $d$, where the likelihood of each word in d is computed. The denominator consists of the count of words $N$ in document $d$.
The lower the perplexity score the better a model generalises. 


\subsection{Silhouette coefficient} \label{research:silhouette}
The silhouette is used to measure between the cohesion and the separation of intra-clusters. In our model this measures the mean intra-cluster distance for each document and compares distance to the nearest-cluster distance.

\[
   \mathlarger{s(i) = \frac{b(i) - a(i)}{\max{\{ a(i), b(i)}\} } }
\]

Where $s_i$ is the silhouette of sample $i$ in the cluster. $a_i$ is the average distance for $i$ from all the objects in the cluster and $b_i$ the distance of $i$ from a cluster $b$ not containing $i$. 

\[
\mathlarger{-1 \leq s \le 1}
\]

The value of $s$ will be contained between $-1$ and $1$. If $s(i) = 1$ then we can say that the distance $i$  is a lot less in its own cluster then the nearest other cluster. If we take $s(i) = -1$ then the similarity of $i$ is higher in the other nearest cluster then its current cluster \cite{Rousseeuw1987Silhouettes:Analysis}.


\subsection{Jensen-Shannon divergence and KL-divergence} \label{research:jsdivergence}
The Kullback Leiber divergence was introduced to measure the density between to distributions \cite{Hershey2007ApproximatingModels}. Based upon this important and popular measure the Jensen-Shannon divergence (JS) was introduced \cite{Fuglede2004Jensen-ShannonEmbedding}. Which is better used to measure similarity between two text documents based on their probability distributions.

\[
\mathlarger{JDS(P||Q) = \frac{1}{2}D(P||M) + \frac{1}{2}D(Q||M)}
\]

Where $P$ and $Q$ denote a probability distribution and $M$ the set of probability distributions. 

\subsection{Human perception}
Although LDA can be used to find latent patterns, explore, tag recommend in a document corpus the final result of topics do not necessarily match up with the human expectation of a topic. Especially in a unsupervised learning model with only mathematical measure. The reason of this paragraph is to make readers aware that the suitability of a model in a unsupervised learning and NLP environment still need support of a human factor \cite{Towne2016MeasuringPerception}.

\section{Data mining}


\section{Machine learning}

